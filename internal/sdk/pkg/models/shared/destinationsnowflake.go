// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type DestinationSnowflakeType string

const (
	DestinationSnowflakeTypeSnowflake DestinationSnowflakeType = "SNOWFLAKE"
)

func (e DestinationSnowflakeType) ToPointer() *DestinationSnowflakeType {
	return &e
}

func (e *DestinationSnowflakeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SNOWFLAKE":
		*e = DestinationSnowflakeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationSnowflakeType: %v", v)
	}
}

type DestinationSnowflake struct {
	Type DestinationSnowflakeType `json:"type"`
	// The universally unique identifier of the destination connection.
	ConnectionID string `json:"connectionId"`
	// If set to `true`, a `Transformation Complete` event is published once a transformation completes, and the pipeline waits for a `Quality Check Complete` event before loading to the destination. Defaults to `false`.
	WaitForQualityCheck *bool `json:"waitForQualityCheck,omitempty"`
	// The destination column names that constitute the primary key. <br> If the pipline has a sharded source include a column that specifies the shard identifier.
	PrimaryKey []string `json:"primaryKey,omitempty"`
	// Whether schema changes detected during transformation should be handled automatically or not. Defaults to `true`.
	AutomaticSchemaChanges *bool `json:"automaticSchemaChanges,omitempty"`
	// The schema in the destination that the tables will be created in. If this is not specified or set to `null` then the schema specified on the connection is used.
	Schema *string `json:"schema,omitempty"`
	Table  string  `json:"table"`
	// If the destination table should retain the history of the source. More information here: https://support.etleap.com/hc/en-us/articles/360008168574. Defaults to `false`.
	RetainHistory *bool `json:"retainHistory,omitempty"`
	// Keys to cluster the table on. If unspecified, the table will use "automatic clustering".
	ClusteringKeys []string `json:"clusteringKeys,omitempty"`
	// Name of a column that indicates the time the record was updated at the destination.
	LastUpdatedColumn *string `json:"lastUpdatedColumn,omitempty"`
}

func (o *DestinationSnowflake) GetType() DestinationSnowflakeType {
	if o == nil {
		return DestinationSnowflakeType("")
	}
	return o.Type
}

func (o *DestinationSnowflake) GetConnectionID() string {
	if o == nil {
		return ""
	}
	return o.ConnectionID
}

func (o *DestinationSnowflake) GetWaitForQualityCheck() *bool {
	if o == nil {
		return nil
	}
	return o.WaitForQualityCheck
}

func (o *DestinationSnowflake) GetPrimaryKey() []string {
	if o == nil {
		return nil
	}
	return o.PrimaryKey
}

func (o *DestinationSnowflake) GetAutomaticSchemaChanges() *bool {
	if o == nil {
		return nil
	}
	return o.AutomaticSchemaChanges
}

func (o *DestinationSnowflake) GetSchema() *string {
	if o == nil {
		return nil
	}
	return o.Schema
}

func (o *DestinationSnowflake) GetTable() string {
	if o == nil {
		return ""
	}
	return o.Table
}

func (o *DestinationSnowflake) GetRetainHistory() *bool {
	if o == nil {
		return nil
	}
	return o.RetainHistory
}

func (o *DestinationSnowflake) GetClusteringKeys() []string {
	if o == nil {
		return nil
	}
	return o.ClusteringKeys
}

func (o *DestinationSnowflake) GetLastUpdatedColumn() *string {
	if o == nil {
		return nil
	}
	return o.LastUpdatedColumn
}
